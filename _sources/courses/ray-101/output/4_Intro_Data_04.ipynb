{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transforming Data\n",
    "\n",
    "- Use either Ray tasks or Ray actors to transform datasets. \n",
    "- Using actors allows for expensive state initialization (e.g., for GPU-based tasks) to be cached.\n",
    "- Ray Data simplifies general purpose parallel GPU and CPU compute in Ray. \n",
    "\n",
    "Here is a sample data pipeline for streaming image data across a classification and segmentation model on a heterogenous cluster of CPUs and GPUs.\n",
    "\n",
    "<img src='https://docs.ray.io/en/releases-2.6.1/_images/stream-example.png' width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform data, we can use the `map_batches` API. This API allows us to apply a transformation to each batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:25:49,233\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:25:49,234\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debf0cd6aa144027a1730b48d094e063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaeb35aa32174da7b0376bf1d53d7ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb630a7f713b44608c45f31e5eaaabf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5fc542b7c744978d6a76e2aeb94598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapBatches(normalize)\n",
       "+- Dataset(\n",
       "      num_rows=?,\n",
       "      schema={image: numpy.ndarray(shape=(28, 28), dtype=uint8), path: string}\n",
       "   )"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "\n",
    "def normalize(\n",
    "    batch: dict[str, np.ndarray], min_: float, max_: float\n",
    ") -> dict[str, np.ndarray]:\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    batch[\"image\"] = [transform(image) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "\n",
    "ds_normalized = ds.map_batches(normalize, fn_kwargs={\"min_\": 0, \"max_\": 255})\n",
    "ds_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution mode\n",
    "\n",
    "- Most transformations are **lazy**. \n",
    "- They **don't execute until you** write a dataset to storage or decide to **materialize** (or consume) the dataset.\n",
    "- To materialize a very small subset of the data, you can use the **`take_batch`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:26:40,187\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:26:40,188\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> LimitOperator[limit=10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81c5672e9e349eb8982271fae7bd8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c12997069324bc89a9c751574583951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd7e0ccb4c64af8b19fa1ef7985755f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(normalize) 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd832f487d884d23b5a32a4643b4474f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=10 4: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb9aa61c98b4ecc857290ead31aa1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalized_batch = ds_normalized.take_batch(batch_size=10)\n",
    "\n",
    "for image in normalized_batch[\"image\"]:\n",
    "    assert image.shape == (1, 28, 28) # channel, height, width\n",
    "    assert image.min() >= -1 and image.max() <= 1 # normalized to [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stateful transformations with actors\n",
    "\n",
    "In cases like **batch inference**, you want to spin up a number of **actor processes** that are initialized once with your model and reused to process multiple batches.\n",
    "\n",
    "To implement this, you can use the `map_batches` API with a \"Callable\" class method that implements:\n",
    "\n",
    "- `__init__`: Initialize any expensive state.\n",
    "- `__call__`: Perform the stateful transformation.\n",
    "\n",
    "For example, we can implement a `MNISTClassifier` that:\n",
    "- loads a pre-trained model from a local file\n",
    "- accepts a batch of images and generates the predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class MNISTClassifier:\n",
    "    def __init__(self, local_path: str):\n",
    "        self.model = torch.jit.load(local_path)\n",
    "        self.model.to(\"cuda\")\n",
    "        self.model.eval()\n",
    "\n",
    "    def __call__(self, batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "        images = torch.tensor(batch[\"image\"]).float().to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(images).cpu().numpy()\n",
    "\n",
    "        batch[\"predicted_label\"] = np.argmax(logits, axis=1)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt to ../../../mnt/cluster_storage/model.pt\n"
     ]
    }
   ],
   "source": [
    "# We download the model from s3 to an EFS storage\n",
    "!aws s3 cp s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt /mnt/cluster_storage/model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `map_batches` API to apply the transformation to each batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_preds = ds_normalized.map_batches(\n",
    "    MNISTClassifier,\n",
    "    fn_constructor_kwargs={\"local_path\": \"/mnt/cluster_storage/model.pt\"},\n",
    "    num_gpus=0.1,\n",
    "    concurrency=1,\n",
    "    batch_size=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<b>Note:</b> We pass in the Callable class uninitialized. Ray will pass in the arguments to the class constructor when the class is actually used in a transformation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:32:17,604\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:32:17,605\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> ActorPoolMapOperator[MapBatches(MNISTClassifier)] -> LimitOperator[limit=100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6beddafcd55b4fa39331c47dca354694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377536a77b2c46d29e581d22d439660d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5226e75c8634d66b06bc059388855db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(normalize) 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f235c00540fc42d1b61713fbde1d55cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(MNISTClassifier) 4: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67495077a9ba4f11b29c726dff36b3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=100 5: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae2d3152f184b128382fdff9b8bbf06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_preds = ds_preds.take_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materializing Data\n",
    "\n",
    "You can choose to materialize the entire dataset into the ray object store which is distributed across the cluster, primarily in memory and secondarily spilling to disk.\n",
    "\n",
    "To materialize the dataset, we can use the `materialize()` method.\n",
    "\n",
    "Use this **only** when you require the full dataset to compute downstream outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:35:32,187\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:35:32,187\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> ActorPoolMapOperator[MapBatches(MNISTClassifier)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14433956907646ab97142199354bbe66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed4da38dad143a0ab2589d323d7063f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88036718ece46b48a40d6ad1660c71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(normalize) 3: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d724ec1140654239ae4ea98ded56fefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(MNISTClassifier) 4: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b53b0cbca374bd7bd7507bb0497270f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5494f7ba227449dba13694a8410960dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MaterializedDataset(\n",
       "   num_blocks=1,\n",
       "   num_rows=500,\n",
       "   schema={\n",
       "      image: numpy.ndarray(shape=(1, 28, 28), dtype=float),\n",
       "      path: string,\n",
       "      predicted_label: int64\n",
       "   }\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_preds.materialize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}