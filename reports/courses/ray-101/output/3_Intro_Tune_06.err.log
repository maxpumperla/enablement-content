Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/site-packages/jupyter_core/utils/__init__.py", line 154, in wrapped
    asyncio.get_running_loop()
RuntimeError: no running event loop

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/site-packages/nbclient/client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/site-packages/jupyter_core/utils/__init__.py", line 158, in wrapped
    return loop.run_until_complete(inner)
  File "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
tuner = tune.Tuner(
    trainable=tune.with_resources(train_pytorch, {"gpu": 1}), # we will dedicate 1 GPU to each trial
    param_space={
        "num_epochs": 1,
        "batch_size": 128,
        "lr": tune.loguniform(1e-4, 1e-1),
    },
    tune_config=tune.TuneConfig(
        mode="min",
        metric="loss",
        num_samples=2,
        search_alg=tune.search.BasicVariantGenerator(),
        scheduler=tune.schedulers.FIFOScheduler(),
    ),
)

results = tuner.fit()
------------------


[0;31m---------------------------------------------------------------------------[0m
[0;31mNameError[0m                                 Traceback (most recent call last)
Cell [0;32mIn[2], line 1[0m
[0;32m----> 1[0m tuner [38;5;241m=[39m [43mtune[49m[38;5;241m.[39mTuner(
[1;32m      2[0m     trainable[38;5;241m=[39mtune[38;5;241m.[39mwith_resources(train_pytorch, {[38;5;124m"[39m[38;5;124mgpu[39m[38;5;124m"[39m: [38;5;241m1[39m}), [38;5;66;03m# we will dedicate 1 GPU to each trial[39;00m
[1;32m      3[0m     param_space[38;5;241m=[39m{
[1;32m      4[0m         [38;5;124m"[39m[38;5;124mnum_epochs[39m[38;5;124m"[39m: [38;5;241m1[39m,
[1;32m      5[0m         [38;5;124m"[39m[38;5;124mbatch_size[39m[38;5;124m"[39m: [38;5;241m128[39m,
[1;32m      6[0m         [38;5;124m"[39m[38;5;124mlr[39m[38;5;124m"[39m: tune[38;5;241m.[39mloguniform([38;5;241m1e-4[39m, [38;5;241m1e-1[39m),
[1;32m      7[0m     },
[1;32m      8[0m     tune_config[38;5;241m=[39mtune[38;5;241m.[39mTuneConfig(
[1;32m      9[0m         mode[38;5;241m=[39m[38;5;124m"[39m[38;5;124mmin[39m[38;5;124m"[39m,
[1;32m     10[0m         metric[38;5;241m=[39m[38;5;124m"[39m[38;5;124mloss[39m[38;5;124m"[39m,
[1;32m     11[0m         num_samples[38;5;241m=[39m[38;5;241m2[39m,
[1;32m     12[0m         search_alg[38;5;241m=[39mtune[38;5;241m.[39msearch[38;5;241m.[39mBasicVariantGenerator(),
[1;32m     13[0m         scheduler[38;5;241m=[39mtune[38;5;241m.[39mschedulers[38;5;241m.[39mFIFOScheduler(),
[1;32m     14[0m     ),
[1;32m     15[0m )
[1;32m     17[0m results [38;5;241m=[39m tuner[38;5;241m.[39mfit()

[0;31mNameError[0m: name 'tune' is not defined

