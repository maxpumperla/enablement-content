{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Intro to Ray Tune\n","\n","This notebook will walk you through the basics of hyperparameter tuning with Ray Tune.\n","\n","<div class=\"alert alert-block alert-info\">\n","<p> Here is the roadmap for this notebook:</p>\n","<ul>\n","    <li> <b>Part 0:</b> Introduction </li>\n","    <li> <b>Part 1:</b> Loading and visualizing data </li>\n","    <li> <b>Part 2:</b> Setting up a PyTorch model</li>\n","    <li> <b>Part 3:</b> Introduction to Ray Tune </li>\n","    <li> <b>Part 4:</b> Diving deeper into Ray Tune concepts </li>\n","    <li> <b>Part 5:</b> Hyperparameter tuning the PyTorch model using Ray Tune </li>\n","</ul>\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Loading and visualizing data\n","\n","**MNIST dataset**\n","\n","- The MNIST dataset consists of handwritten digits (0-9).\n","- Training set: 60,000 images\n","- Test set: 10,000 images\n","- Image size: 28x28 pixels\n","- Number of classes: 10 (digits 0-9)\n","- Format: 2D array of pixel values, where each pixel is a grayscale intensity between 0 (black) and 255 (white).\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch\n","from torchvision.datasets import MNIST\n","from torchvision.transforms import Compose, ToTensor, Normalize\n","from torch.utils.data import DataLoader\n","\n","\n","def build_data_loader(batch_size: int) -> DataLoader:\n","    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n","    train_data = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n","    data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n","    return data_loader"]},{"cell_type":"markdown","metadata":{},"source":["Let's visualize a batch"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 2000x200 with 10 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","\n","fig, axs = plt.subplots(1, 10, figsize=(20, 2))\n","\n","data_loader = build_data_loader(batch_size=10)\n","\n","for (images, labels) in data_loader:\n","    \n","    for i, (image, label) in enumerate(zip(images, labels)):\n","        axs[i].imshow(image.squeeze(), cmap=\"gray\")\n","        axs[i].set_title(label.item())\n","        axs[i].axis(\"off\")\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Setting up a PyTorch model\n","\n","Here is a high level overview of the model training process:\n","\n","- **Objective**: Classify handwritten digits (0-9)\n","- **Model**: Simple Neural Network using PyTorch\n","- **Evaluation Metric**: Accuracy\n","- **Dataset**: MNIST\n","\n","We'll start with a basic PyTorch implementation to establish a baseline before moving on to more advanced techniques. This will give us a good foundation for understanding the benefits of hyperparameter tuning and distributed training in later sections."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from torchvision.models import resnet18\n","from torch.optim import Adam\n","from torch.nn import CrossEntropyLoss\n","\n","\n","def train_loop_torch(num_epochs: int = 2, batch_size: int = 128, lr: float = 1e-5):\n","    criterion = CrossEntropyLoss()\n","\n","    model = resnet18()\n","    model.conv1 = torch.nn.Conv2d(\n","        1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","    )\n","    \n","    model.to(\"cuda\")\n","    data_loader = build_data_loader(batch_size)\n","    optimizer = Adam(model.parameters(), lr=lr)\n","\n","    for epoch in range(num_epochs):\n","        for images, labels in data_loader:\n","            images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Report the metrics\n","        print(f\"Epoch {epoch}, Loss: {loss}\")"]},{"cell_type":"markdown","metadata":{},"source":["We fit the model by submitting it onto a GPU node using Ray Core"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0, Loss: 0.326001912355423\n","Epoch 1, Loss: 0.20302368700504303\n"]}],"source":["train_loop_torch(num_epochs=2)"]},{"cell_type":"markdown","metadata":{},"source":["**Can we do any better ?** let's see if we can tune the hyperparameters of our model to get a better loss.\n","\n","But hyperparameter tuning is a computationally expensive task, and it will take a long time to run sequentially.\n","\n","[Ray Tune](https://docs.ray.io/en/master/tune/) is a distributed hyperparameter tuning library that can help us speed up the process!"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Introduction to Ray Tune"]},{"cell_type":"markdown","metadata":{},"source":["\n","<img src=\"https://docs.ray.io/en/master/_images/tune_overview.png\" width=\"250\">\n","\n","Tune is a Python library for experiment execution and hyperparameter tuning at any scale."]},{"cell_type":"markdown","metadata":{},"source":["### Getting started\n","\n","We start by defining our training function"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import ray\n","from ray import tune, train\n","from ray.tune.search import optuna\n","import numpy as np\n","from typing import Any\n","\n","\n","def my_simple_model(distance: np.ndarray, a: float) -> np.ndarray:\n","    return distance * a\n","\n","# Step 1: Define the training function\n","def train_my_simple_model(config: dict[str, Any]) -> None: # Expected function signature for Ray Tune\n","    distances = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n","    total_amts = distances * 10\n","    \n","    a = config[\"a\"]\n","    predictions = my_simple_model(distances, a)\n","    rmse = np.sqrt(np.mean((total_amts - predictions) ** 2))\n","\n","    train.report({\"rmse\": rmse}) # This is how we report the metric to Ray Tune"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Note:</b> how the training function needs to accept a config argument. This is because Ray Tune will pass the hyperparameters to the training function as a dictionary.\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["Next, we define and run the hyperparameter tuning job by following these steps:\n","\n","1. Create a `Tuner` object (in our case named `tuner`)\n","2. Call `tuner.fit`"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div class=\"tuneStatus\">\n","  <div style=\"display: flex;flex-direction: row\">\n","    <div style=\"display: flex;flex-direction: column;\">\n","      <h3>Tune Status</h3>\n","      <table>\n","<tbody>\n","<tr><td>Current time:</td><td>2024-11-29 09:13:31</td></tr>\n","<tr><td>Running for: </td><td>00:00:03.34        </td></tr>\n","<tr><td>Memory:      </td><td>4.7/31.0 GiB       </td></tr>\n","</tbody>\n","</table>\n","    </div>\n","    <div class=\"vDivider\"></div>\n","    <div class=\"systemInfo\">\n","      <h3>System Info</h3>\n","      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/16 CPUs, 0/2 GPUs (0.0/1.0 anyscale/node-group:1xT4:8CPU-32GB, 0.0/2.0 anyscale/provider:aws, 0.0/2.0 anyscale/region:us-west-2, 0.0/2.0 anyscale/accelerator_shape:1xT4, 0.0/2.0 accelerator_type:T4, 0.0/1.0 anyscale/node-group:head)\n","    </div>\n","    \n","  </div>\n","  <div class=\"hDivider\"></div>\n","  <div class=\"trialStatus\">\n","    <h3>Trial Status</h3>\n","    <table>\n","<thead>\n","<tr><th>Trial name                       </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">  a</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   rmse</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>train_my_simple_model_3207e_00000</td><td>TERMINATED</td><td>10.0.35.222:27211</td><td style=\"text-align: right;\">  6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000382423</td><td style=\"text-align: right;\">1.32665</td></tr>\n","<tr><td>train_my_simple_model_3207e_00001</td><td>TERMINATED</td><td>10.0.35.222:27212</td><td style=\"text-align: right;\">  5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000378847</td><td style=\"text-align: right;\">1.65831</td></tr>\n","<tr><td>train_my_simple_model_3207e_00002</td><td>TERMINATED</td><td>10.0.20.35:7721  </td><td style=\"text-align: right;\">  5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000359058</td><td style=\"text-align: right;\">1.65831</td></tr>\n","<tr><td>train_my_simple_model_3207e_00003</td><td>TERMINATED</td><td>10.0.20.35:7722  </td><td style=\"text-align: right;\"> 19</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000357389</td><td style=\"text-align: right;\">2.98496</td></tr>\n","<tr><td>train_my_simple_model_3207e_00004</td><td>TERMINATED</td><td>10.0.20.35:7725  </td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000418901</td><td style=\"text-align: right;\">2.98496</td></tr>\n","</tbody>\n","</table>\n","  </div>\n","</div>\n","<style>\n",".tuneStatus {\n","  color: var(--jp-ui-font-color1);\n","}\n",".tuneStatus .systemInfo {\n","  display: flex;\n","  flex-direction: column;\n","}\n",".tuneStatus td {\n","  white-space: nowrap;\n","}\n",".tuneStatus .trialStatus {\n","  display: flex;\n","  flex-direction: column;\n","}\n",".tuneStatus h3 {\n","  font-weight: bold;\n","}\n",".tuneStatus .hDivider {\n","  border-bottom-width: var(--jp-border-width);\n","  border-bottom-color: var(--jp-border-color0);\n","  border-bottom-style: solid;\n","}\n",".tuneStatus .vDivider {\n","  border-left-width: var(--jp-border-width);\n","  border-left-color: var(--jp-border-color0);\n","  border-left-style: solid;\n","  margin: 0.5em 1em 0.5em 1em;\n","}\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2024-11-29 09:13:31,837\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/ray/ray_results/train_my_simple_model_2024-11-29_09-13-26' in 0.0075s.\n","2024-11-29 09:13:31,841\tINFO tune.py:1041 -- Total run time: 3.57 seconds (3.33 seconds for the tuning loop).\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(autoscaler +4m37s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n","\u001b[36m(train_pytorch pid=38448)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","\u001b[36m(train_pytorch pid=38448)\u001b[0m Failed to download (trying next):\n","\u001b[36m(train_pytorch pid=38448)\u001b[0m HTTP Error 403: Forbidden\n","\u001b[36m(train_pytorch pid=38448)\u001b[0m \n","\u001b[36m(train_pytorch pid=38448)\u001b[0m Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","\u001b[36m(train_pytorch pid=38448)\u001b[0m Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]}],"source":["# Step 2: Set up the Tuner\n","tuner = tune.Tuner(\n","    trainable=train_my_simple_model,  # Training function or class to be tuned\n","    param_space={\n","        \"a\": tune.randint(0, 20),  # Hyperparameter: a\n","    },\n","    tune_config=tune.TuneConfig(\n","        metric=\"rmse\",  # Metric to optimize (minimize)\n","        mode=\"min\",     # Minimize the metric\n","        num_samples=5,  # Number of samples to try\n","    ),\n",")\n","\n","# Step 3: Run the Tuner and get the results\n","results = tuner.fit()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["Result(\n","  metrics={'rmse': 1.3266499161421599},\n","  path='/home/ray/ray_results/train_my_simple_model_2024-11-29_09-13-26/train_my_simple_model_3207e_00000_0_a=6_2024-11-29_09-13-28',\n","  filesystem='local',\n","  checkpoint=None\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Step 4: Get the best result\n","best_result = results.get_best_result()\n","best_result"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["{'a': 6}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["best_result.config"]},{"cell_type":"markdown","metadata":{},"source":["So let's recap what actually happened here ?\n","\n","```python\n","tuner = tune.Tuner(\n","    trainable=train_my_simple_model,  # Training function or class to be tuned\n","    param_space={\n","        \"a\": tune.randint(0, 20),  # Hyperparameter: a\n","    },\n","    tune_config=tune.TuneConfig(\n","        metric=\"rmse\",  # Metric to optimize (minimize)\n","        mode=\"min\",     # Minimize the metric\n","        num_samples=5,  # Number of samples to try\n","    ),\n",")\n","\n","results = tuner.fit()\n","```\n","\n","A Tuner accepts:\n","- A training function or class which is specified by `trainable`\n","- A search space which is specified by `param_space`\n","- A metric to optimize which is specified by `metric` and the direction of optimization `mode`\n","- `num_samples` which correlates to the number of trials to run\n","\n","`tuner.fit` then runs multiple trials in parallel, each with a different set of hyperparameters, and returns the best set of hyperparameters found.\n"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Diving deeper into Ray Tune concepts\n","\n","- How does the Tuner **which resources to allocate** to trials?\n","    - Each trial will run in a separate process and consume 1 CPU core.\n","- How does it decide **how to tune** - i.e. which trials to run next?\n","    - Ray Tune uses a search algorithm to decide which trials to run next.\n","    - e.g. A random search, or a more sophisticated search algorithm like a bayesian optimization algorithm.\n","- How does it decide **when to stop** - i.e. whether to kill a trial early?\n","    - e.g. If a trial is performing poorly compared to other trials, it perhaps makes sense to stop it early (successive halving, hyperband)\n","    - Ray Tune uses a scheduler to decide if/when to stop trials, or to prioritize certain trials over others."]},{"cell_type":"markdown","metadata":{},"source":["Below is a diagram showing the relationship between the different Ray Tune components we have discussed.\n","\n","<img src=\"https://docs.ray.io/en/latest/_images/tune_flow.png\" width=\"800\" />\n","\n","\n","To learn more about the key tune concepts, you can visit the [Ray Tune documentation here](https://docs.ray.io/en/master/tune/key-concepts.html)."]},{"cell_type":"markdown","metadata":{},"source":["### Default settings for Ray Tune"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tuner = tune.Tuner(\n","    # This is how to specify resources for your trainable function\n","    trainable=tune.with_resources(train_my_simple_model, {\"cpu\": 1}),\n","    param_space={\"a\": tune.randint(0, 20)},\n","    tune_config=tune.TuneConfig(\n","        mode=\"min\",\n","        metric=\"rmse\",\n","        num_samples=5, \n","        # This search algorithm is a basic variation (i.e random/grid search) based on parameter space\n","        search_alg=tune.search.BasicVariantGenerator(), \n","        # This scheduler is very simple: no early stopping, just run all trials in submission order\n","        scheduler=tune.schedulers.FIFOScheduler(), \n","    ),\n",")\n","results = tuner.fit()"]},{"cell_type":"markdown","metadata":{},"source":["Below is a diagram showing the relationship between the different Ray Tune components we have discussed.\n","\n","<img src=\"https://docs.ray.io/en/latest/_images/tune_flow.png\" width=\"800\" />\n","\n","\n","To learn more about the key tune concepts, you can visit the [Ray Tune documentation here](https://docs.ray.io/en/master/tune/key-concepts.html)."]},{"cell_type":"markdown","metadata":{},"source":["### Annotated experiment table\n","\n","<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/attentive-ray-101/experiment_table_annotated.png\" width=\"800\" />\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Exercise\n","\n","<div class=\"alert alert-block alert-info\">\n","    \n","__Lab activity: Finetune a linear regression model.__\n","    \n","\n","Given the below code to train a linear regression model from scratch: \n","\n","```python\n","def train_linear_model(lr: float, epochs: int) -> None:\n","    x = np.array([0, 1, 2, 3, 4])\n","    y = x * 2\n","    w = 0\n","    for _ in range(epochs):\n","        loss = np.sqrt(np.mean((w * x - y) ** 2))\n","        dl_dw = np.mean(2 * x * (w * x - y)) \n","        w -= lr * dl_dw\n","        print({\"rmse\": loss})\n","\n","# Hint: Step 1 update the function signature\n","\n","# Hint: Step 2 Create the tuner object\n","tuner = tune.Tuner(...)\n","\n","# Hint: Step 3: Run the tuner\n","results = tuner.fit()\n","```\n","\n","Use Ray Tune to tune the hyperparameters `lr` and `epochs`. \n","\n","Perform a search using the optuna.OptunaSearch search algorithm with 5 samples over the following ranges:\n","- `lr`: loguniform(1e-4, 1e-1)\n","- `epochs`: randint(1, 100)\n","\n","</div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Write your code here\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","<details>\n","<summary>Click here to view the solution</summary>\n","\n","```python\n","def train_linear_model(config) -> None:\n","    epochs = config[\"epochs\"]\n","    lr = config[\"lr\"]\n","    x = np.array([0, 1, 2, 3, 4])\n","    y = x * 2\n","    w = 0\n","    for _ in range(epochs):\n","        loss = np.sqrt(np.mean((w * x - y) ** 2))\n","        dl_dw = np.mean(2 * x * (w * x - y)) \n","        w -= lr * dl_dw\n","        train.report({\"rmse\": loss})\n","\n","tuner = tune.Tuner(\n","    trainable=train_linear_model,  # Training function or class to be tuned\n","    param_space={\n","        \"lr\": tune.loguniform(1e-4, 1e-1),  # Hyperparameter: learning rate\n","        \"epochs\": tune.randint(1, 100),  # Hyperparameter: number of epochs\n","    },\n","    tune_config=tune.TuneConfig(\n","        metric=\"rmse\",  # Metric to optimize (minimize)\n","        mode=\"min\",     # Minimize the metric\n","        num_samples=5,  # Number of samples to try\n","        search_alg=optuna.OptunaSearch(), # Use Optuna for hyperparameter search\n","    ),\n",")\n","\n","results = tuner.fit()\n","```\n","\n","</details>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Hyperparameter tuning the PyTorch model using Ray Tune\n","\n","The first step is to move in all the PyTorch code into a function that we can pass to the `trainable` argument of the `tune.run` function."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def train_pytorch(config): # we change the function so it accepts a config dictionary\n","    criterion = CrossEntropyLoss()\n","\n","    model = resnet18()\n","    model.conv1 = torch.nn.Conv2d(\n","        1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","    )\n","    model.to(\"cuda\")\n","\n","    optimizer = Adam(model.parameters(), lr=config[\"lr\"])\n","    \n","    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n","    train_data = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n","    data_loader = DataLoader(train_data, batch_size=config[\"batch_size\"], shuffle=True, drop_last=True)\n","\n","    for epoch in range(config[\"num_epochs\"]):\n","        for images, labels in data_loader:\n","            images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Report the metrics using train.report instead of print\n","        train.report({\"loss\": loss.item()})"]},{"cell_type":"markdown","metadata":{},"source":["The second and third steps are the same as before. We define the tuner and run it by calling the fit method."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div class=\"tuneStatus\">\n","  <div style=\"display: flex;flex-direction: row\">\n","    <div style=\"display: flex;flex-direction: column;\">\n","      <h3>Tune Status</h3>\n","      <table>\n","<tbody>\n","<tr><td>Current time:</td><td>2024-11-29 09:44:37</td></tr>\n","<tr><td>Running for: </td><td>00:00:25.36        </td></tr>\n","<tr><td>Memory:      </td><td>4.6/31.0 GiB       </td></tr>\n","</tbody>\n","</table>\n","    </div>\n","    <div class=\"vDivider\"></div>\n","    <div class=\"systemInfo\">\n","      <h3>System Info</h3>\n","      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/16 CPUs, 1.0/2 GPUs (0.0/1.0 anyscale/node-group:1xT4:8CPU-32GB, 0.0/2.0 accelerator_type:T4, 0.0/2.0 anyscale/region:us-west-2, 0.0/2.0 anyscale/provider:aws, 0.0/2.0 anyscale/accelerator_shape:1xT4, 0.0/1.0 anyscale/node-group:head)\n","    </div>\n","    \n","  </div>\n","  <div class=\"hDivider\"></div>\n","  <div class=\"trialStatus\">\n","    <h3>Trial Status</h3>\n","    <table>\n","<thead>\n","<tr><th>Trial name               </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     loss</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>train_pytorch_7cf0c_00000</td><td>TERMINATED</td><td>10.0.35.222:38448</td><td style=\"text-align: right;\">0.0582891 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         19.9064</td><td style=\"text-align: right;\">0.264131 </td></tr>\n","<tr><td>train_pytorch_7cf0c_00001</td><td>TERMINATED</td><td>10.0.20.35:10307 </td><td style=\"text-align: right;\">0.00787705</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         20.2805</td><td style=\"text-align: right;\">0.0564279</td></tr>\n","</tbody>\n","</table>\n","  </div>\n","</div>\n","<style>\n",".tuneStatus {\n","  color: var(--jp-ui-font-color1);\n","}\n",".tuneStatus .systemInfo {\n","  display: flex;\n","  flex-direction: column;\n","}\n",".tuneStatus td {\n","  white-space: nowrap;\n","}\n",".tuneStatus .trialStatus {\n","  display: flex;\n","  flex-direction: column;\n","}\n",".tuneStatus h3 {\n","  font-weight: bold;\n","}\n",".tuneStatus .hDivider {\n","  border-bottom-width: var(--jp-border-width);\n","  border-bottom-color: var(--jp-border-color0);\n","  border-bottom-style: solid;\n","}\n",".tuneStatus .vDivider {\n","  border-left-width: var(--jp-border-width);\n","  border-left-color: var(--jp-border-color0);\n","  border-left-style: solid;\n","  margin: 0.5em 1em 0.5em 1em;\n","}\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/9912422 [00:00<?, ?it/s]\n","  1%|          | 98304/9912422 [00:00<00:11, 831953.25it/s]\n","  4%|▍         | 393216/9912422 [00:00<00:05, 1806326.67it/s]\n"," 16%|█▌        | 1572864/9912422 [00:00<00:01, 5521900.47it/s]\n"," 62%|██████▏   | 6127616/9912422 [00:00<00:00, 18478655.81it/s]\n","100%|██████████| 9912422/9912422 [00:00<00:00, 18409805.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(train_pytorch pid=38448)\u001b[0m Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\u001b[36m(train_pytorch pid=38448)\u001b[0m \n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m \n","\u001b[36m(train_pytorch pid=38448)\u001b[0m \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 507557.46it/s]\n","100%|██████████| 9912422/9912422 [00:00<00:00, 16263535.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(train_pytorch pid=38448)\u001b[0m Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\u001b[36m(train_pytorch pid=38448)\u001b[0m \n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m \n","\u001b[36m(train_pytorch pid=38448)\u001b[0m \n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m \n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 4649632.58it/s]\n","100%|██████████| 28881/28881 [00:00<00:00, 490189.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(train_pytorch pid=38448)\u001b[0m \n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m \n","\u001b[36m(train_pytorch pid=38448)\u001b[0m \n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m \n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\u001b[32m [repeated 12x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(train_pytorch pid=38448)\u001b[0m \n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m \n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m Failed to download (trying next):\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m HTTP Error 403: Forbidden\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m \n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m \n","\u001b[36m(train_pytorch pid=10307, ip=10.0.20.35)\u001b[0m Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\u001b[32m [repeated 6x across cluster]\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 3523960.19it/s]\u001b[32m [repeated 7x across cluster]\u001b[0m\n","100%|██████████| 1648877/1648877 [00:00<00:00, 4641500.47it/s]\u001b[32m [repeated 10x across cluster]\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["2024-11-29 09:44:37,315\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/ray/ray_results/train_pytorch_2024-11-29_09-44-11' in 0.0033s.\n","2024-11-29 09:44:37,319\tINFO tune.py:1041 -- Total run time: 25.37 seconds (25.36 seconds for the tuning loop).\n"]}],"source":["tuner = tune.Tuner(\n","    trainable=tune.with_resources(train_pytorch, {\"gpu\": 1}), # we will dedicate 1 GPU to each trial\n","    param_space={\n","        \"num_epochs\": 1,\n","        \"batch_size\": 128,\n","        \"lr\": tune.loguniform(1e-4, 1e-1),\n","    },\n","    tune_config=tune.TuneConfig(\n","        mode=\"min\",\n","        metric=\"loss\",\n","        num_samples=2,\n","        search_alg=tune.search.BasicVariantGenerator(),\n","        scheduler=tune.schedulers.FIFOScheduler(),\n","    ),\n",")\n","\n","results = tuner.fit()"]},{"cell_type":"markdown","metadata":{},"source":["Finally, we can get the best result and its configuration:"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["{'num_epochs': 1, 'batch_size': 128, 'lr': 0.007877049646500664}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["best_result = results.get_best_result()\n","best_result.config"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":2}
