{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Data\n",
    "\n",
    "- Datasets uses Ray tasks to read data from remote storage. \n",
    "- When reading from a file-based datasource (e.g., S3), it creates a number of read tasks proportional to the number of CPUs in the cluster. \n",
    "- Each read task reads its assigned files and produces an output block\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-summit/rag-app/dataset-read-cropped-v2.svg\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some `MNIST` data from s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE 0/\n",
      "                           PRE 1/\n",
      "                           PRE 2/\n",
      "                           PRE 3/\n",
      "                           PRE 4/\n",
      "                           PRE 5/\n",
      "                           PRE 6/\n",
      "                           PRE 7/\n",
      "                           PRE 8/\n",
      "                           PRE 9/\n"
     ]
    }
   ],
   "source": [
    "# Here is our dataset it contains 50 images per class\n",
    "!aws s3 ls s3://anyscale-public-materials/ray-ai-libraries/mnist/50_per_index/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `read_images` function to load the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:56:54,059\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:56:54,060\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e32ffe4eae490998463c6a620a73ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7882960eae5d42bea50f4585afca3b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7777647ff92d40e785779ffc4c20a688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 09:56:57,428\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-12-06_07-31-15_546129_2446/logs/ray-data\n",
      "2024-12-06 09:56:57,429\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978b065386b146a09252f866cbeecab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e879325570674bcb9c2a34be9eb28958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df21126c52f4d978fbf15db93177ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3265f9c37d43e9a2bc1f1016b50385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dataset(\n",
       "   num_rows=?,\n",
       "   schema={image: numpy.ndarray(shape=(28, 28), dtype=uint8), path: string}\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ds = ray.data.read_images(\"s3://anyscale-public-materials/ray-ai-libraries/mnist/50_per_index/\", include_paths=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the [Input/Output docs](https://docs.ray.io/en/latest/data/api/input_output.html) for a comprehensive list of read functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More about Datasets\n",
    "\n",
    "- A Dataset consists of a list of Ray object references to\u00a0**blocks**. \n",
    "- Having multiple blocks in a dataset allows for **parallel transformation and ingest**.\n",
    "\n",
    "The following figure visualizes a **tabular dataset with three blocks, each block holding 1000 rows each**:\n",
    "\n",
    "<img src='https://docs.ray.io/en/releases-2.6.1/_images/dataset-arch.svg' width=50%/>\n",
    "\n",
    "- A Dataset is just a list of Ray object references.\n",
    "- Fits into Ray's general compute framework.\n",
    "- It can be freely passed between Ray tasks, actors, and other  libraries like any other object reference.\n",
    "- This flexibility is a unique characteristic of Ray Datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}